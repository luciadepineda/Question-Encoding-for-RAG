# Optimizing Information Retrieval: A Deep Dive into Question Encoding Techniques for Retrieval-Augmented Generation
This project focuses on a comprehensive exploration of encoding strategies within the RAG architecture, with a specific emphasis on the question encoder. The study draws inspiration from existing literature, implementing a systematic evaluation of various question encoding approaches. Using the Retrieval-Augmented Generation Benchmark (RGB) for rigorous assessment, the project aims to understand how different encoding choices impact the robustness and effectiveness of RAG models. The implementation, conducted in Python using the Transformers library and PyTorch, explores diverse question encoding techniques, leveraging pre-trained models like Sentence Transformers. The evaluation incorporates modifications to the RAG model and employs RGB testbeds for detailed analysis.

**Methodology**:

To integrate the RAG models into the RGB framework, several modifications are essential. These changes include the addition of the RAG models to the _models.py_ file, ensuring compatibility with the RGB evaluation scripts. In this file, pre-trained models are stored. These models are subjected to evaluation on various testbeds to assess their performance in different aspects of RAG.

The changes are made in both _models.py_ and _evalue.py_ files. Specifically, the class **RagModelFT** is built in the models file. This includes the instantiation and configuration of the RAG model, implemented using the Transformers library and PyTorch and specifying the question encoder used. This parameter can be passed as an argument in the command line to make the evaluation more straight forward. Moreover, the class RagModelFT also includes the generate method, responsible for generating sequences. It takes several input parameters, including input ids, attention mask, context input ids, context attention mask, doc scores, and other related parameters. This method uses the RAG modelâ€™s generate function to produce sequences, but making sure the correct format and parameters are given. 

In addition, the predict function of the file _evalue.py_, was also modified. This function is responsible for generating predictions using a specified model and the changes made are for handling the case when the provided model is a RagModelFT. To do that, it processes the inputs with the corresponding tokenizer, as well as retrieving relevant documents and computing doc scores.

With these modifications, we are able to run the RGB evaluate function for our specific RAG models.
